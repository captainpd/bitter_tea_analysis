{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3ciq9MDjEx/HkuW36XLM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/captainpd/bitter_tea_analysis/blob/main/bitter_tea_analys_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "veOh9kG0ypq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "791218cf-9532-4b92-adb9-c960ef797730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bitter_tea_analysis'...\n",
            "remote: Enumerating objects: 257, done.\u001b[K\n",
            "remote: Counting objects: 100% (257/257), done.\u001b[K\n",
            "remote: Compressing objects: 100% (238/238), done.\u001b[K\n",
            "remote: Total 257 (delta 23), reused 241 (delta 12), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (257/257), 3.85 MiB | 17.15 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/captainpd/bitter_tea_analysis.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd bitter_tea_analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zm9UYjKtZ8i2",
        "outputId": "44b8c306-50ac-4495-86ef-edaab0aab5db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bitter_tea_analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhQcWkgwcQ0n",
        "outputId": "d41095af-5372-40eb-9037-af3c99955608"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.11.2)\n",
            "Collecting gradio (from -r requirements.txt (line 2))\n",
            "  Downloading gradio-4.13.0-py3-none-any.whl (16.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->-r requirements.txt (line 1)) (2.5)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 2))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 2)) (4.2.2)\n",
            "Collecting fastapi (from gradio->-r requirements.txt (line 2))\n",
            "  Downloading fastapi-0.108.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 2))\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.8.0 (from gradio->-r requirements.txt (line 2))\n",
            "  Downloading gradio_client-0.8.0-py3-none-any.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.1/305.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio->-r requirements.txt (line 2))\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 2)) (0.20.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 2)) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 2)) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 2)) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 2))\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 2)) (9.4.0)\n",
            "Collecting pydantic>=2.0 (from gradio->-r requirements.txt (line 2))\n",
            "  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio->-r requirements.txt (line 2))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio->-r requirements.txt (line 2))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 2)) (6.0.1)\n",
            "Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 2))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 2))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 2)) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 2))\n",
            "  Downloading uvicorn-0.25.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.0->gradio->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.8.0->gradio->-r requirements.txt (line 2))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 2)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 2)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 2)) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio->-r requirements.txt (line 2)) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio->-r requirements.txt (line 2)) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 2)) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 2)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 2)) (2023.3.post1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio->-r requirements.txt (line 2))\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.6 (from pydantic>=2.0->gradio->-r requirements.txt (line 2))\n",
            "  Downloading pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio->-r requirements.txt (line 2))\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 2)) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 2))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 2))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 2)) (13.7.0)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 2))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.33.0,>=0.29.0 (from fastapi->gradio->-r requirements.txt (line 2))\n",
            "  Downloading starlette-0.32.0.post1-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 2)) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx->gradio->-r requirements.txt (line 2))\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 2)) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 2)) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 2)) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 2)) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 2)) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=b7dea9fe3168e7abe0b3955d0894684244ff7f6bf36ffad64b3c3fa9fc79a647\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, typing-extensions, tomlkit, shellingham, semantic-version, python-multipart, orjson, h11, colorama, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, httpcore, pydantic, httpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.6.0 colorama-0.4.6 fastapi-0.108.0 ffmpy-0.3.1 gradio-4.13.0 gradio-client-0.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 orjson-3.9.10 pydantic-2.5.3 pydantic-core-2.14.6 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.32.0.post1 tomlkit-0.12.0 typing-extensions-4.9.0 uvicorn-0.25.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fetch_news import fetch_news\n",
        "\n",
        "fetch_news(r\"data/news\", interval_time=0.2)"
      ],
      "metadata": {
        "id": "zH_mu0MZaBMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d19f11-fbe2-4c71-ae29-2a39ed067e24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Downloading news ==\n",
            "fetching 2024-01-08.txt\n",
            "fetching 2024-01-07.txt\n",
            "fetching 2024-01-06.txt\n",
            "fetching 2024-01-05.txt\n",
            "fetching 2024-01-04.txt\n",
            "fetching 2024-01-03.txt\n",
            "fetching 2024-01-02.txt\n",
            "fetching 2024-01-01.txt\n",
            "fetching 2023-12-31.txt\n",
            "fetching 2023-12-30.txt\n",
            "fetching 2023-12-29.txt\n",
            "fetching 2023-12-28.txt\n",
            "fetching 2023-12-27.txt\n",
            "fetching 2023-12-26.txt\n",
            "fetching 2023-12-25.txt\n",
            "fetching 2023-12-24.txt\n",
            "fetching 2023-12-23.txt\n",
            "fetching 2023-12-22.txt\n",
            "fetching 2023-12-21.txt\n",
            "fetching 2023-12-20.txt\n",
            "fetching 2023-12-19.txt\n",
            "fetching 2023-12-18.txt\n",
            "fetching 2023-12-17.txt\n",
            "fetching 2023-12-16.txt\n",
            "fetching 2023-12-15.txt\n",
            "fetching 2023-12-14.txt\n",
            "fetching 2023-12-13.txt\n",
            "fetching 2023-12-12.txt\n",
            "fetching 2023-12-11.txt\n",
            "fetching 2023-12-10.txt\n",
            "fetching 2023-12-09.txt\n",
            "fetching 2023-12-08.txt\n",
            "fetching 2023-12-07.txt\n",
            "fetching 2023-12-06.txt\n",
            "fetching 2023-12-05.txt\n",
            "fetching 2023-12-04.txt\n",
            "fetching 2023-12-03.txt\n",
            "fetching 2023-12-02.txt\n",
            "fetching 2023-12-01.txt\n",
            "fetching 2023-11-30.txt\n",
            "fetching 2023-11-29.txt\n",
            "fetching 2023-11-28.txt\n",
            "fetching 2023-11-27.txt\n",
            "fetching 2023-11-26.txt\n",
            "fetching 2023-11-25.txt\n",
            "fetching 2023-11-24.txt\n",
            "fetching 2023-11-23.txt\n",
            "fetching 2023-11-22.txt\n",
            "fetching 2023-11-21.txt\n",
            "fetching 2023-11-20.txt\n",
            "fetching 2023-11-19.txt\n",
            "fetching 2023-11-18.txt\n",
            "fetching 2023-11-17.txt\n",
            "fetching 2023-11-16.txt\n",
            "fetching 2023-11-15.txt\n",
            "fetching 2023-11-14.txt\n",
            "fetching 2023-11-13.txt\n",
            "fetching 2023-11-12.txt\n",
            "fetching 2023-11-11.txt\n",
            "fetching 2023-11-10.txt\n",
            "fetching 2023-11-09.txt\n",
            "fetching 2023-11-08.txt\n",
            "fetching 2023-11-07.txt\n",
            "fetching 2023-11-06.txt\n",
            "fetching 2023-11-05.txt\n",
            "fetching 2023-11-04.txt\n",
            "fetching 2023-11-03.txt\n",
            "fetching 2023-11-02.txt\n",
            "fetching 2023-11-01.txt\n",
            "fetching 2023-10-31.txt\n",
            "fetching 2023-10-30.txt\n",
            "fetching 2023-10-29.txt\n",
            "fetching 2023-10-28.txt\n",
            "fetching 2023-10-27.txt\n",
            "fetching 2023-10-26.txt\n",
            "fetching 2023-10-25.txt\n",
            "fetching 2023-10-24.txt\n",
            "fetching 2023-10-23.txt\n",
            "fetching 2023-10-22.txt\n",
            "fetching 2023-10-21.txt\n",
            "fetching 2023-10-20.txt\n",
            "fetching 2023-10-19.txt\n",
            "fetching 2023-10-18.txt\n",
            "fetching 2023-10-17.txt\n",
            "fetching 2023-10-16.txt\n",
            "fetching 2023-10-15.txt\n",
            "fetching 2023-10-14.txt\n",
            "fetching 2023-10-13.txt\n",
            "fetching 2023-10-12.txt\n",
            "fetching 2023-10-11.txt\n",
            "fetching 2023-10-10.txt\n",
            "fetching 2023-10-09.txt\n",
            "fetching 2023-10-08.txt\n",
            "fetching 2023-10-07.txt\n",
            "fetching 2023-10-06.txt\n",
            "fetching 2023-10-05.txt\n",
            "fetching 2023-10-04.txt\n",
            "fetching 2023-10-03.txt\n",
            "fetching 2023-10-02.txt\n",
            "fetching 2023-10-01.txt\n",
            "fetching 2023-09-30.txt\n",
            "fetching 2023-09-29.txt\n",
            "fetching 2023-09-28.txt\n",
            "fetching 2023-09-27.txt\n",
            "fetching 2023-09-26.txt\n",
            "fetching 2023-09-25.txt\n",
            "fetching 2023-09-24.txt\n",
            "fetching 2023-09-23.txt\n",
            "fetching 2023-09-22.txt\n",
            "fetching 2023-09-21.txt\n",
            "fetching 2023-09-20.txt\n",
            "fetching 2023-09-19.txt\n",
            "fetching 2023-09-18.txt\n",
            "fetching 2023-09-17.txt\n",
            "fetching 2023-09-16.txt\n",
            "fetching 2023-09-15.txt\n",
            "fetching 2023-09-14.txt\n",
            "fetching 2023-09-13.txt\n",
            "fetching 2023-09-12.txt\n",
            "fetching 2023-09-11.txt\n",
            "fetching 2023-09-10.txt\n",
            "fetching 2023-09-09.txt\n",
            "fetching 2023-09-08.txt\n",
            "fetching 2023-09-07.txt\n",
            "fetching 2023-09-05.txt\n",
            "fetching 2023-09-04.txt\n",
            "fetching 2023-09-03.txt\n",
            "fetching 2023-09-02.txt\n",
            "fetching 2023-09-01.txt\n",
            "fetching 2023-08-31.txt\n",
            "fetching 2023-08-30.txt\n",
            "fetching 2023-08-29.txt\n",
            "fetching 2023-08-28.txt\n",
            "fetching 2023-08-27.txt\n",
            "fetching 2023-08-26.txt\n",
            "fetching 2023-08-25.txt\n",
            "fetching 2023-08-24.txt\n",
            "fetching 2023-08-23.txt\n",
            "fetching 2023-08-22.txt\n",
            "fetching 2023-08-21.txt\n",
            "fetching 2023-08-20.txt\n",
            "fetching 2023-08-19.txt\n",
            "fetching 2023-08-18.txt\n",
            "fetching 2023-08-17.txt\n",
            "fetching 2023-08-16.txt\n",
            "fetching 2023-08-15.txt\n",
            "fetching 2023-08-14.txt\n",
            "fetching 2023-08-13.txt\n",
            "fetching 2023-08-12.txt\n",
            "fetching 2023-08-11.txt\n",
            "fetching 2023-08-10.txt\n",
            "fetching 2023-08-09.txt\n",
            "fetching 2023-08-08.txt\n",
            "fetching 2023-08-07.txt\n",
            "fetching 2023-08-06.txt\n",
            "fetching 2023-08-05.txt\n",
            "fetching 2023-08-04.txt\n",
            "fetching 2023-08-03.txt\n",
            "fetching 2023-08-02.txt\n",
            "fetching 2023-08-01.txt\n",
            "fetching 2023-07-31.txt\n",
            "fetching 2023-07-30.txt\n",
            "fetching 2023-07-29.txt\n",
            "fetching 2023-07-28.txt\n",
            "fetching 2023-07-27.txt\n",
            "fetching 2023-07-26.txt\n",
            "fetching 2023-07-25.txt\n",
            "fetching 2023-07-24.txt\n",
            "fetching 2023-07-23.txt\n",
            "fetching 2023-07-22.txt\n",
            "fetching 2023-07-21.txt\n",
            "fetching 2023-07-20.txt\n",
            "fetching 2023-07-19.txt\n",
            "fetching 2023-07-18.txt\n",
            "fetching 2023-07-17.txt\n",
            "fetching 2023-07-16.txt\n",
            "fetching 2023-07-15.txt\n",
            "fetching 2023-07-14.txt\n",
            "fetching 2023-07-13.txt\n",
            "fetching 2023-07-12.txt\n",
            "fetching 2023-07-11.txt\n",
            "fetching 2023-07-10.txt\n",
            "fetching 2023-07-09.txt\n",
            "fetching 2023-07-08.txt\n",
            "fetching 2023-07-07.txt\n",
            "fetching 2023-07-06.txt\n",
            "fetching 2023-07-05.txt\n",
            "fetching 2023-07-04.txt\n",
            "fetching 2023-07-03.txt\n",
            "fetching 2023-07-02.txt\n",
            "fetching 2023-07-01.txt\n",
            "fetching 2023-06-30.txt\n",
            "fetching 2023-06-29.txt\n",
            "fetching 2023-06-28.txt\n",
            "fetching 2023-06-27.txt\n",
            "fetching 2023-06-26.txt\n",
            "fetching 2023-06-25.txt\n",
            "2023-06-25.txt already exists\n",
            "fetching 2023-06-24.txt\n",
            "fetching 2023-06-23.txt\n",
            "fetching 2023-06-22.txt\n",
            "fetching 2023-06-21.txt\n",
            "fetching 2023-06-20.txt\n",
            "fetching 2023-06-19.txt\n",
            "fetching 2023-06-18.txt\n",
            "fetching 2023-06-17.txt\n",
            "fetching 2023-06-16.txt\n",
            "fetching 2023-06-15.txt\n",
            "fetching 2023-06-14.txt\n",
            "fetching 2023-06-13.txt\n",
            "fetching 2023-06-12.txt\n",
            "fetching 2023-06-11.txt\n",
            "fetching 2023-06-10.txt\n",
            "fetching 2023-06-09.txt\n",
            "fetching 2023-06-08.txt\n",
            "fetching 2023-06-07.txt\n",
            "fetching 2023-06-06.txt\n",
            "fetching 2023-06-05.txt\n",
            "fetching 2023-06-04.txt\n",
            "fetching 2023-06-03.txt\n",
            "fetching 2023-06-02.txt\n",
            "fetching 2023-06-01.txt\n",
            "fetching 2023-05-31.txt\n",
            "fetching 2023-05-30.txt\n",
            "2023-05-30.txt already exists\n",
            "fetching 2023-05-29.txt\n",
            "fetching 2023-05-28.txt\n",
            "fetching 2023-05-27.txt\n",
            "fetching 2023-05-26.txt\n",
            "fetching 2023-05-25.txt\n",
            "2023-05-25.txt already exists\n",
            "fetching 2023-05-24.txt\n",
            "fetching 2023-05-23.txt\n",
            "fetching 2023-05-22.txt\n",
            "fetching 2023-05-21.txt\n",
            "fetching 2023-05-20.txt\n",
            "fetching 2023-05-19.txt\n",
            "fetching 2023-05-18.txt\n",
            "fetching 2023-05-17.txt\n",
            "fetching 2023-05-16.txt\n",
            "fetching 2023-05-15.txt\n",
            "fetching 2023-05-14.txt\n",
            "fetching 2023-05-13.txt\n",
            "fetching 2023-05-12.txt\n",
            "Error 404: Unable to fetch the page\n",
            "Network ERROR STOPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from fetch_news import fetch_news\n",
        "from text_analysis import word_combine, word_count\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Tab(label=\"下载数据\"):\n",
        "        button_download = gr.Button(value=\"下载数据\")\n",
        "        text_download_path = gr.Text(value=r\"data/news\")\n",
        "        button_download.click(fetch_news, inputs=[text_download_path])\n",
        "\n",
        "    with gr.Tab(label=\"同时出现统计\"):\n",
        "        str_repeat_words = \",\".join(['美国', '元首'])\n",
        "\n",
        "        text_combine = gr.Text(label=\"同时出现词汇\", value=str_repeat_words)\n",
        "        button_combine = gr.Button(value=\"搜索同时出现词汇\")\n",
        "        json_result_combine = gr.Json(label=\"统计结果\")\n",
        "        button_combine.click(word_combine, inputs=[text_download_path, text_combine], outputs=[json_result_combine])\n",
        "\n",
        "    with gr.Tab(label=\"关键词次数统计\"):\n",
        "        str_repeat_words = \",\".join(['朝鲜', '美国', '台湾', '巴西', '以色列', '乌克兰', '意大利'])\n",
        "\n",
        "        text_repeat = gr.Text(label=\"统计词汇\", value=str_repeat_words)\n",
        "        button_repeat = gr.Button(value=\"搜索重复词汇\")\n",
        "        json_result = gr.Json(label=\"统计结果\")\n",
        "\n",
        "        button_repeat.click(word_count, inputs=[text_download_path, text_repeat], outputs=[json_result])\n",
        "\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epNcqOC7eTxu",
        "outputId": "9b01ef00-e6e9-4b6b-97fb-6cb812ec4800"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2233, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/bitter_tea_analysis/webui.py\", line 30, in <module>\n",
            "    demo.launch(debug=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2129, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2235, in block_thread\n",
            "    print(\"Keyboard interruption in main thread... closing server.\")\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Git commands\n",
        "\n",
        "clone - bring a repository hosted somewhere else(like github) to your local machine\n",
        "\n",
        "add - track new files and changes in git\n",
        "\n",
        "commit - save your change in git\n",
        "\n",
        "push - upload local changes to remote repository\n",
        "\n",
        "pull - download changes from remote repository to local machine"
      ],
      "metadata": {
        "id": "lyfkvurZzk5Q"
      }
    }
  ]
}